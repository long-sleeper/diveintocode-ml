{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint　自然言語処理入門  \n",
    "\n",
    "### ＜目的＞  \n",
    "- 自然言語処理の一連の流れを学ぶ\n",
    "- 自然言語のベクトル化の方法を学ぶ\n",
    "\n",
    "### ＜自然言語のベクトル化＞  \n",
    "\n",
    "**自然言語処理（NLP, Natural Language Processing）** とは人間が普段使っている **自然言語** をコンピュータに処理させる技術のことです。ここではその中でも、機械学習の入力として自然言語を用いることを考えていきます。  \n",
    "多くの機械学習手法は **数値データ（量的変数）** の入力を前提にしていますので、自然言語の **テキストデータ** を数値データに変換する必要があります。これを **自然言語のベクトル化** と呼びます。ベクトル化の際にテキストデータの特徴をうまく捉えられるよう、様々な手法が考えられてきていますので、このSprintではそれらを学びます。  \n",
    "\n",
    "### ＜非構造化データ＞  \n",
    "データの分類として、表に数値がまとめられたようなコンピュータが扱いやすい形を **構造化データ** 、人間が扱いやすい画像・動画・テキスト・音声などを **非構造化データ** と呼ぶことがあります。自然言語のベクトル化は、非構造化データを構造化データに変換する工程と言えます。同じ非構造化データでも、画像に対してはディープラーニングを用いる場合この変換作業はあまり必要がありませんでしたが、テキストにおいてはこれをどう行うかが重要です。\n",
    "\n",
    "### ＜自然言語処理により何ができるか＞  \n",
    "機械学習の入力や出力に自然言語のテキストを用いることで様々なことができます。入力も出力もテキストである例としては **機械翻訳** があげられ、実用化されています。入力は画像で出力がテキストである **画像キャプション生成** やその逆の文章からの画像生成も研究が進んでいます。  \n",
    "しかし、出力をテキストや画像のような非構造化データとすることは難易度が高いです。比較的簡単にできることとしては、入力をテキスト、出力をカテゴリーとする **テキスト分類** です。  \n",
    "アヤメやタイタニック、手書き数字のような定番の存在として、**IMDB映画レビューデータセット** の感情分析があります。レビューの文書が映画に対して肯定的か否定的かを2値分類します。文書ごとの肯定・否定はラベルが与えられています。このSprintではこれを使っていきます。\n",
    "\n",
    "\n",
    "### ＜IMDB映画レビューデータセットの準備＞  \n",
    "IMDB映画レビューデータセットを準備します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "# ローカルにダウンロードし、7-zipで解凍した\n",
    "train_review = load_files('./aclImdb/train/', encoding='utf-8')\n",
    "x_train, y_train = train_review.data, train_review.target\n",
    "test_review = load_files('./aclImdb/test/', encoding='utf-8')\n",
    "x_test, y_test = test_review.data, test_review.target\n",
    "# ラベルの0,1と意味の対応の表示\n",
    "print(train_review.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. <br /><br />Flawed but honest with a terrible honesty.\n"
     ]
    }
   ],
   "source": [
    "print(\"x : {}\".format(x_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDBはInternet Movie Databaseの略で、映画のデータベースサイトです。\n",
    "\n",
    "\n",
    "- Ratings and Reviews for New Movies and TV Shows - IMDb\n",
    "\n",
    "\n",
    "このサイトではユーザーが映画に対して1から10点の評価とコメントを投稿することができます。そのデータベースから訓練データは25000件、テストデータは25000件のデータセットを作成しています。\n",
    "\n",
    "\n",
    "4点以下を否定的、7点以下を肯定的なレビューとして2値のラベル付けしており、これにより感情の分類を行います。5,6点の中立的なレビューはデータセットに含んでいません。また、ラベルは訓練用・テスト用それぞれで均一に入っています。詳細はダウンロードしたREADMEを確認してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ＜古典的な手法＞\n",
    "\n",
    "古典的ながら現在でも強力な手法であるBoWとTF-IDFを見ていきます。\n",
    "\n",
    "\n",
    "### ＜BoW＞\n",
    "\n",
    "単純ながら効果的な方法として BoW (Bag of Words) があります。これは、サンプルごとに単語などの 登場回数 を数えたものをベクトルとする方法です。単語をカテゴリとして捉え one-hot表現 していることになります。\n",
    "\n",
    "例として、IMDBデータセットからある3文の最初の5単語を抜き出したものを用意しました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_dataset = \\\n",
    "  [\"This movie is very good.\",\n",
    "  \"This film is a good\",\n",
    "  \"Very bad. Very, very bad.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この3文にBoWを適用させてみます。scikit-learnのCountVectorizerを利用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>bad</th>\n",
       "      <th>film</th>\n",
       "      <th>good</th>\n",
       "      <th>is</th>\n",
       "      <th>movie</th>\n",
       "      <th>this</th>\n",
       "      <th>very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  bad  film  good  is  movie  this  very\n",
       "0  0    0     0     1   1      1     1     1\n",
       "1  1    0     1     1   1      0     1     0\n",
       "2  0    2     0     0   0      0     0     3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b')\n",
    "bow = (vectorizer.fit_transform(mini_dataset)).toarray()\n",
    "# DataFrameにまとめる\n",
    "df = pd.DataFrame(bow, columns=vectorizer.get_feature_names())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例にあげた3文の中で登場する8種類の単語が列名になり、0,1,2番目のサンプルでそれらが何回登場しているかを示しています。2番目のサンプル「Very bad. Very, very bad.」ではbadが2回、veryが3回登場しています。列名になっている言葉はデータセットが持つ **語彙** と呼びます。\n",
    "\n",
    "テキストはBoWにより各サンプルが語彙数の次元を持つ特徴量となり、機械学習モデルへ入力できるようになります。この時使用したテキスト全体のことを **コーパス** と呼びます。語彙はコーパスに含まれる言葉よって決まり、それを特徴量としてモデルの学習を行います。そのため、テストデータではじめて登場する語彙はベクトル化される際に無視されます。\n",
    "\n",
    "### ＜前処理＞\n",
    "CountVectorizerクラスでは大文字は小文字に揃えるという **前処理** が自動的に行われています。こういった前処理は自然言語処理において大切で、不要な記号などの消去（テキストクリーニング）や表記揺れの統一といったことを別途行うことが一般的です。\n",
    "\n",
    "\n",
    "語形が「see」「saw」「seen」のように変化する単語に対して語幹に揃える ステミング と呼ばれる処理を行うこともあります。\n",
    "\n",
    "\n",
    "### ＜トークン＞\n",
    "BoWは厳密には単語を数えているのではなく、 **トークン（token）** として定めた固まりを数えます。\n",
    "\n",
    "\n",
    "何をトークンとするかはCountVectorizerでは引数``token_pattern``で **正規表現** の記法により指定されます。デフォルトは``r'(?u)\\b\\w\\w+\\b'``ですが、上の例では``r'(?u)\\b\\w+\\b'``としています。\n",
    "\n",
    "\n",
    "デフォルトでは空白・句読点・スラッシュなどに囲まれた2文字以上の文字を1つのトークンとして抜き出すようになっているため、「a」や「I」などがカウントされません。英語では1文字の単語は文章の特徴をあまり表さないため、除外されることもあります。しかし、上の例では1文字の単語もトークンとして抜き出すように引数を指定しています。\n",
    "\n",
    "\n",
    "### 《正規表現》\n",
    "\n",
    "\n",
    "正規表現は前処理の際にも活用しますが、ここでは詳細は扱いません。Pythonではreモジュールによって正規表現操作ができます。\n",
    "\n",
    "\n",
    "re — 正規表現操作\n",
    "\n",
    "\n",
    "正規表現を利用する際はリアルタイムで結果を確認できる以下のようなサービスが便利です。\n",
    "\n",
    "\n",
    "Online regex tester and debugger: PHP, PCRE, Python, Golang and JavaScript\n",
    "\n",
    "\n",
    "### ＜形態素解析＞\n",
    "英語などの多くの言語では空白という分かりやすい基準でトークン化が行えますが、日本語ではそれが行えません。\n",
    "\n",
    "\n",
    "日本語では名詞や助詞、動詞のように異なる **品詞** で分けられる単位で **分かち書き** することになります。例えば「私はプログラミングを学びます」という日本語の文は「私/は/プログラミング/を/学び/ます」という風になります。\n",
    "\n",
    "\n",
    "これには **MeCab** や **Janome** のような形態素解析ツールを用います。Pythonから利用することも可能です。MeCabをウェブ上で簡単に利用できるWeb茶まめというサービスも国立国語研究所が提供しています。\n",
    "\n",
    "\n",
    "自然言語では新しい言葉も日々生まれますので、それにどれだけ対応できるかも大切です。MeCab用の毎週更新される辞書として **mecab-ipadic-NEologd** がオープンソースで存在しています。\n",
    "\n",
    "mecab-ipadic-neologd/README.ja.md at master · neologd/mecab-ipadic-neologd\n",
    "\n",
    "\n",
    "### ＜n-gram＞\n",
    "上のBoWの例では1つの単語（トークン）毎の登場回数を数えましたが、これでは語順は全く考慮されていません。\n",
    "\n",
    "\n",
    "考慮するために、隣あう単語同士をまとめて扱う **n-gram** という考え方を適用することがあります。2つの単語をまとめる場合は **2-gram (bigram)** と呼び、次のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a good</th>\n",
       "      <th>bad very</th>\n",
       "      <th>film is</th>\n",
       "      <th>is a</th>\n",
       "      <th>is very</th>\n",
       "      <th>movie is</th>\n",
       "      <th>this film</th>\n",
       "      <th>this movie</th>\n",
       "      <th>very bad</th>\n",
       "      <th>very good</th>\n",
       "      <th>very very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a good  bad very  film is  is a  is very  movie is  this film  this movie  \\\n",
       "0       0         0        0     0        1         1          0           1   \n",
       "1       1         0        1     1        0         0          1           0   \n",
       "2       0         1        0     0        0         0          0           0   \n",
       "\n",
       "   very bad  very good  very very  \n",
       "0         0          1          0  \n",
       "1         0          0          0  \n",
       "2         2          0          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ngram_rangeで利用するn-gramの範囲を指定する\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 2), token_pattern=r'(?u)\\b\\w+\\b')\n",
    "bow_train = (vectorizer.fit_transform(mini_dataset)).toarray()\n",
    "df = pd.DataFrame(bow_train, columns=vectorizer.get_feature_names())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-gramにより「very good」と「very bad」が区別して数えられています。\n",
    "\n",
    "\n",
    "単語をまとめない場合は **1-gram (unigram)** と呼びます。3つまとめる3-gram(trigram)など任意の数を考えることができます。1-gramと2-gramを組み合わせてBoWを行うといったこともあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】BoWのスクラッチ実装\n",
    "以下の3文のBoWを求められるプログラムをscikit-learnを使わずに作成してください。1-gramと2-gramで計算してください。\n",
    "\n",
    "This movie is SOOOO funny!!!  \n",
    "What a movie! I never  \n",
    "best movie ever!!!!! this movie  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class ScratchCountVectorizer:\n",
    "    def __init__(self, ngram_range, token_pattern):\n",
    "        self.ngram_range = ngram_range\n",
    "        self.token_pattern = token_pattern\n",
    "        self.dicts = []\n",
    "        self.vocabulary_ = {}\n",
    "    \n",
    "    def fit(self, sentences):\n",
    "        # scikit-learnのn_gram設定法に準拠\n",
    "        s, t = self.ngram_range\n",
    "        for n in range(s, t+1):\n",
    "            for i in range(len(sentences)):\n",
    "                # まず1単語のリスト取得\n",
    "                vec = re.findall(self.token_pattern, sentences[i].lower())\n",
    "                words = []\n",
    "                # n_gram数分のまとまりで取得\n",
    "                for j in range(len(vec)-n+1):\n",
    "                    word = ' '.join(vec[j:j+n])\n",
    "                    words.append(word)\n",
    "                # これらをリストとして格納\n",
    "                keys, values = np.unique(words, return_counts=True)\n",
    "                d =  dict(zip(keys, values))\n",
    "                self.dicts.append(d)\n",
    "                # Counterで、辞書をまとめていく\n",
    "                c1 = Counter(self.vocabulary_)\n",
    "                c2 = Counter(d)\n",
    "                self.vocabulary_ = dict(c1 + c2)\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def fit_transform(self, sentences):\n",
    "        # まずfitさせる\n",
    "        self.fit(sentences)\n",
    "        # n_gram設定で取得された語彙一覧を取得\n",
    "        vec = sorted(list(self.vocabulary_.keys()))\n",
    "        # row, col, dataを初期化\n",
    "        row = []\n",
    "        col = []\n",
    "        data = []\n",
    "        s, t = self.ngram_range\n",
    "        # fitと同じ処理\n",
    "        for n in range(s, t+1):\n",
    "            for i in range(len(sentences)):\n",
    "                words = re.findall(self.token_pattern, sentences[i].lower())\n",
    "                for j in range(len(words)-n+1):\n",
    "                    word = ' '.join(words[j:j+n])\n",
    "                    # 以降でrow, col, dataを埋める\n",
    "                    data.append(1)\n",
    "                    row.append(i)\n",
    "                    col.append(vec.index(word))\n",
    "        # scipyのcsr_matrixを通して出力（scikit-learnに準拠）\n",
    "        return csr_matrix((data, (row, col)))\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        # 語彙一覧の取得\n",
    "        return sorted(list(self.vocabulary_.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>best</th>\n",
       "      <th>ever</th>\n",
       "      <th>funny</th>\n",
       "      <th>i</th>\n",
       "      <th>is</th>\n",
       "      <th>movie</th>\n",
       "      <th>never</th>\n",
       "      <th>soooo</th>\n",
       "      <th>this</th>\n",
       "      <th>what</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  best  ever  funny  i  is  movie  never  soooo  this  what\n",
       "0  0     0     0      1  0   1      1      0      1     1     0\n",
       "1  1     0     0      0  1   0      1      1      0     0     1\n",
       "2  0     1     1      0  0   0      2      0      0     1     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scratch (1 gram)\n",
    "sentences = [\"This movie is SOOOO funny!!!\",\n",
    "   \"What a movie! I never\",\n",
    "   \"best movie ever!!!!! this movie\"]\n",
    "\n",
    "s = ScratchCountVectorizer(ngram_range=(1, 1), token_pattern=r'(?u)\\b\\w+\\b')\n",
    "bow = s.fit_transform(sentences).toarray()\n",
    "df = pd.DataFrame(bow, columns=s.get_feature_names())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a movie</th>\n",
       "      <th>best movie</th>\n",
       "      <th>ever this</th>\n",
       "      <th>i never</th>\n",
       "      <th>is soooo</th>\n",
       "      <th>movie ever</th>\n",
       "      <th>movie i</th>\n",
       "      <th>movie is</th>\n",
       "      <th>soooo funny</th>\n",
       "      <th>this movie</th>\n",
       "      <th>what a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a movie  best movie  ever this  i never  is soooo  movie ever  movie i  \\\n",
       "0        0           0          0        0         1           0        0   \n",
       "1        1           0          0        1         0           0        1   \n",
       "2        0           1          1        0         0           1        0   \n",
       "\n",
       "   movie is  soooo funny  this movie  what a  \n",
       "0         1            1           1       0  \n",
       "1         0            0           0       1  \n",
       "2         0            0           1       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scratch (2 gram)\n",
    "s = ScratchCountVectorizer(ngram_range=(2, 2), token_pattern=r'(?u)\\b\\w+\\b')\n",
    "bow = s.fit_transform(sentences).toarray()\n",
    "df = pd.DataFrame(bow, columns=s.get_feature_names())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>a movie</th>\n",
       "      <th>best</th>\n",
       "      <th>best movie</th>\n",
       "      <th>ever</th>\n",
       "      <th>ever this</th>\n",
       "      <th>funny</th>\n",
       "      <th>i</th>\n",
       "      <th>i never</th>\n",
       "      <th>is</th>\n",
       "      <th>...</th>\n",
       "      <th>movie ever</th>\n",
       "      <th>movie i</th>\n",
       "      <th>movie is</th>\n",
       "      <th>never</th>\n",
       "      <th>soooo</th>\n",
       "      <th>soooo funny</th>\n",
       "      <th>this</th>\n",
       "      <th>this movie</th>\n",
       "      <th>what</th>\n",
       "      <th>what a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  a movie  best  best movie  ever  ever this  funny  i  i never  is  ...  \\\n",
       "0  0        0     0           0     0          0      1  0        0   1  ...   \n",
       "1  1        1     0           0     0          0      0  1        1   0  ...   \n",
       "2  0        0     1           1     1          1      0  0        0   0  ...   \n",
       "\n",
       "   movie ever  movie i  movie is  never  soooo  soooo funny  this  this movie  \\\n",
       "0           0        0         1      0      1            1     1           1   \n",
       "1           0        1         0      1      0            0     0           0   \n",
       "2           1        0         0      0      0            0     1           1   \n",
       "\n",
       "   what  what a  \n",
       "0     0       0  \n",
       "1     1       1  \n",
       "2     0       0  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scratch (1,2 gram)\n",
    "s = ScratchCountVectorizer(ngram_range=(1, 2), token_pattern=r'(?u)\\b\\w+\\b')\n",
    "bow = s.fit_transform(sentences).toarray()\n",
    "df = pd.DataFrame(bow, columns=s.get_feature_names())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ＜TF-IDF＞\n",
    "\n",
    "BoWの発展的手法として TF-IDF もよく使われます。これは Term Frequency (TF) と Inverse Document Frequency (IDF) という2つの指標の組み合わせです。\n",
    "\n",
    "\n",
    "**《標準的なTF-IDFの式》**\n",
    "\n",
    "\n",
    "Term Frequency:\n",
    "\n",
    "$$\n",
    "tf(t,d) = \\frac{n_{t,d}}{\\sum_{s \\in d}n_{s,d}}\n",
    "$$\n",
    "\n",
    "$n_{t,d}$ : サンプルd内のトークンtの出現回数（BoWと同じ）\n",
    "$\\sum_{s \\in d}n_{s,d}$ : サンプルdの全トークンの出現回数の和\n",
    "\n",
    "\n",
    "Inverse Document Frequency:\n",
    "\n",
    "$$\n",
    "idf(t) = \\log{\\frac{N}{df(t)}}\n",
    "$$\n",
    "\n",
    "$N$ : サンプル数\n",
    "$df(t)$ : トークンtが出現するサンプル数\n",
    "\n",
    "\n",
    "＊logの底は任意の値\n",
    "\n",
    "\n",
    "TF-IDF:\n",
    "\n",
    "$$\n",
    "tfidf(t, d) = tf(t, d) \\times idf(t)\n",
    "$$\n",
    "\n",
    "### ＜IDF＞\n",
    "IDFはそのトークンがデータセット内で珍しいほど値が大きくなる指標です。\n",
    "\n",
    "\n",
    "サンプル数 $N$ をIMDB映画レビューデータセットの訓練データに合わせ25000として、トークンが出現するサンプル数 $df(t)$ を変化させたグラフを確認してみると、次のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 25000\n",
    "idf = np.log(n_samples/np.arange(1,n_samples))\n",
    "plt.title(\"IDF\")\n",
    "plt.xlabel(\"df(t)\")\n",
    "plt.ylabel(\"IDF\")\n",
    "plt.plot(idf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDFではこの数を出現回数に掛け合わせるので、珍しいトークンの登場に重み付けを行なっていることになります。\n",
    "\n",
    "\n",
    "### ＜ストップワード＞\n",
    "あまりにも頻繁に登場するトークンは、値を小さくするだけでなく、取り除くという前処理を加えることもあります。取り除くもののことを **ストップワード** と呼びます。既存のストップワード一覧を利用したり、しきい値によって求めたりします。\n",
    "\n",
    "\n",
    "scikit-learnのCountVectorizerでは引数stop_wordsにリストで指定することで処理を行なってくれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>bad</th>\n",
       "      <th>film</th>\n",
       "      <th>good</th>\n",
       "      <th>movie</th>\n",
       "      <th>this</th>\n",
       "      <th>very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  bad  film  good  movie  this  very\n",
       "0  0    0     0     1      1     1     1\n",
       "1  1    0     1     1      0     1     0\n",
       "2  0    2     0     0      0     0     3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=[\"is\"], token_pattern=r'\\b\\w+\\b')\n",
    "bow_train = (vectorizer.fit_transform(mini_dataset)).toarray()\n",
    "df = pd.DataFrame(bow_train, columns=vectorizer.get_feature_names())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代表的な既存のストップワード一覧としては、**NLTK** という自然言語処理のライブラリのものがあげられます。あるデータセットにおいては特別重要な意味を持つ単語が一覧に含まれている可能性もあるため、使用する際は中身を確認することが望ましいです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "print(stop[:10])\n",
    "type(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逆に、登場回数が特に少ないトークンも取り除くことが多いです。全てのトークンを用いるとベクトルの次元数が著しく大きくなってしまい計算コストが高まるためです。\n",
    "\n",
    "\n",
    "scikit-learnのCountVectorizerでは引数max_featuresに最大の語彙数を指定することで処理を行なってくれます。以下の例では出現数が多い順に5個でベクトル化しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "      <th>is</th>\n",
       "      <th>this</th>\n",
       "      <th>very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bad  good  is  this  very\n",
       "0    0     1   1     1     1\n",
       "1    0     1   1     1     0\n",
       "2    2     0   0     0     3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b', max_features = 5)\n",
    "bow_train = (vectorizer.fit_transform(mini_dataset)).toarray()\n",
    "df = pd.DataFrame(bow_train, columns=vectorizer.get_feature_names())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】TF-IDFの計算  \n",
    "IMDB映画レビューデータセットをTF-IDFによりベクトル化してください。NLTKのストップワードを利用し、最大の語彙数は5000程度に設定してください。テキストクリーニングやステミングなどの前処理はこの問題では要求しません。\n",
    "\n",
    "TF-IDFの計算にはscikit-learnの以下のどちらかのクラスを使用してください。\n",
    "\n",
    "sklearn.feature_extraction.text.TfidfVectorizer — scikit-learn 0.21.3 documentation\n",
    "sklearn.feature_extraction.text.TfidfTransformer — scikit-learn 0.21.3 documentation\n",
    "\n",
    "なお、scikit-learnでは標準的な式とは異なる式が採用されています。\n",
    "また、デフォルトでは``norm=\"l2\"``の引数が設定されており、各サンプルにL2正規化が行われます。``norm=None``とすることで正規化は行われなくなります。\n",
    "\n",
    "Term Frequency:\n",
    "\n",
    "$$\n",
    "tf(t,d) = n_{t,d}\n",
    "$$\n",
    "\n",
    "$n_{t,d}$ : サンプルd内のトークンtの出現回数\n",
    "\n",
    "scikit-learnのTFは分母がなくなりBoWと同じ計算になります。\n",
    "\n",
    "Inverse Document Frequency:\n",
    "\n",
    "$$\n",
    "idf(t) = \\log{\\frac{1+N}{1+df(t)}}+1\n",
    "$$\n",
    "\n",
    "$N$ : サンプル数\n",
    "$df(t)$ : トークンtが出現するサンプル数\n",
    "\n",
    "\n",
    "＊logの底はネイピア数e\n",
    "詳細は以下のドキュメントを確認してください。\n",
    "5.2.3.4. Tf–idf term weighting — scikit-learn 0.21.3 documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>13th</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>z</th>\n",
       "      <th>zero</th>\n",
       "      <th>zizek</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  00  000  1  10  100  11  12  13  13th  ...  york  young  younger  \\\n",
       "0      0   0    0  0   0    0   0   0   0     0  ...     0      2        0   \n",
       "1      0   0    0  0   0    0   0   0   0     0  ...     0      0        0   \n",
       "2      0   0    0  0   1    0   0   0   0     0  ...     0      0        0   \n",
       "3      0   0    0  0   1    0   0   0   0     0  ...     0      0        0   \n",
       "4      0   0    0  0   0    0   0   0   0     0  ...     0      0        0   \n",
       "...   ..  ..  ... ..  ..  ...  ..  ..  ..   ...  ...   ...    ...      ...   \n",
       "24995  0   0    0  0   0    1   0   0   0     0  ...     2      0        0   \n",
       "24996  0   0    0  0   0    0   0   0   0     0  ...     0      0        0   \n",
       "24997  0   0    0  0   1    0   0   0   0     0  ...     0      0        0   \n",
       "24998  0   0    0  1   0    0   0   0   0     0  ...     0      0        0   \n",
       "24999  0   0    0  0   0    0   0   0   0     0  ...     0      0        0   \n",
       "\n",
       "       youth  z  zero  zizek  zombie  zombies  zone  \n",
       "0          0  0     1      0       0        0     0  \n",
       "1          0  0     0      0       0        0     0  \n",
       "2          0  0     0      0       0        0     0  \n",
       "3          0  0     0      0       0        0     0  \n",
       "4          0  0     0      0       0        0     0  \n",
       "...      ... ..   ...    ...     ...      ...   ...  \n",
       "24995      0  0     0      0       0        0     0  \n",
       "24996      0  0     0      0       0        0     0  \n",
       "24997      0  0     0      0       0        0     0  \n",
       "24998      0  0     0      0       0        0     0  \n",
       "24999      0  0     0      0       0        0     0  \n",
       "\n",
       "[25000 rows x 5000 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b',\n",
    "                             ngram_range=(1,1),\n",
    "                             stop_words=stop,\n",
    "                             max_features=5000)\n",
    "bow = (vectorizer.fit_transform(x_train)).toarray()\n",
    "df = pd.DataFrame(bow, columns=vectorizer.get_feature_names())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】TF-IDFを用いた学習\n",
    "問題2で求めたベクトルを用いてIMDB映画レビューデータセットの学習・推定を行なってください。モデルは2値分類が行える任意のものを利用してください。\n",
    "\n",
    "\n",
    "ここでは精度の高さは求めませんが、最大の語彙数やストップワード、n-gramの数を変化させて影響を検証してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True)\n",
    "X_train = tfidf.fit_transform(vectorizer.fit_transform(x_train)).toarray()\n",
    "X_test = tfidf.fit_transform(vectorizer.fit_transform(x_test)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Logistic Regression ==\n",
      "tf-idf(1_gram, max_features=5000, L2(+))\n",
      "Accuracy :  0.53532\n"
     ]
    }
   ],
   "source": [
    "# ロジスティック回帰で学習\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print('== Logistic Regression ==')\n",
    "print('tf-idf(1_gram, max_features=5000, L2(+))')\n",
    "print('Accuracy : ', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ほとんど当て推量の精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Logistic Regression ==\n",
      "tf-idf(1_gram, max_features=5000, L2(-))\n",
      "Accuracy :  0.50912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\tf115\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# 正規化なし\n",
    "vectorizer = CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b',\n",
    "                             ngram_range=(1,1),\n",
    "                             stop_words=stop,\n",
    "                             max_features=5000)\n",
    "tfidf = TfidfTransformer(norm=None, use_idf=True, smooth_idf=True)\n",
    "X_train = tfidf.fit_transform(vectorizer.fit_transform(x_train)).toarray()\n",
    "X_test = tfidf.fit_transform(vectorizer.fit_transform(x_test)).toarray()\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print('== Logistic Regression ==')\n",
    "print('tf-idf(1_gram, max_features=5000, L2(-))')\n",
    "print('Accuracy : ', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2正規化はかけたほうがよさそう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Logistic Regression ==\n",
      "tf-idf(1,2_gram, max_features=5000, L2(+))\n",
      "Accuracy :  0.60624\n"
     ]
    }
   ],
   "source": [
    "# 1,2 gram\n",
    "vectorizer = CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b',\n",
    "                             ngram_range=(1,2), \n",
    "                             stop_words=stop,\n",
    "                             max_features=5000)\n",
    "tfidf = TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True)\n",
    "X_train = tfidf.fit_transform(vectorizer.fit_transform(x_train)).toarray()\n",
    "X_test = tfidf.fit_transform(vectorizer.fit_transform(x_test)).toarray()\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print('== Logistic Regression ==')\n",
    "print('tf-idf(1,2_gram, max_features=5000, L2(+))')\n",
    "print('Accuracy : ', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "やはり1 gram単独よりもいい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Logistic Regression ==\n",
      "tf-idf(1_gram, max_features=2500, L2(+))\n",
      "Accuracy :  0.55784\n"
     ]
    }
   ],
   "source": [
    "# max_features = 2500\n",
    "vectorizer = CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b',\n",
    "                             ngram_range=(1,2), \n",
    "                             stop_words=stop,\n",
    "                             max_features=2500)\n",
    "tfidf = TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True)\n",
    "X_train = tfidf.fit_transform(vectorizer.fit_transform(x_train)).toarray()\n",
    "X_test = tfidf.fit_transform(vectorizer.fit_transform(x_test)).toarray()\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print('== Logistic Regression ==')\n",
    "print('tf-idf(1_gram, max_features=2500, L2(+))')\n",
    "print('Accuracy : ', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最大の特徴量数は2500の方が若干精度良く、5000だと余計な単語も含まれているようだ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】TF-IDFのスクラッチ実装\n",
    "以下の3文のTF-IDFを求められるプログラムをscikit-learnを使わずに作成してください。標準的な式と、scikit-learnの採用している式の2種類を作成してください。正規化は不要です。\n",
    "\n",
    "This movie is SOOOO funny!!!  \n",
    "What a movie! I never  \n",
    "best movie ever!!!!! this movie  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchTfidfTransformer:\n",
    "    \n",
    "    def __init__(self, standard, smooth_idf):\n",
    "        self.standard = standard\n",
    "        self.smooth_idf = smooth_idf\n",
    "        \n",
    "    def fit_transform(self, BoW):\n",
    "        \n",
    "        if self.standard:\n",
    "            # diverの式\n",
    "            tf = BoW.toarray()\n",
    "            tf_sum = np.sum(tf, axis=1)[:,None]\n",
    "            tf = tf/tf_sum\n",
    "            df = np.where(tf==0, 0, 1)\n",
    "            df = np.sum(df, axis=0)\n",
    "            idf = np.log(tf.shape[0]/df)\n",
    "        \n",
    "        else:\n",
    "            # scikit-learnの式（smooth_idfでさらに場合分け）\n",
    "            if self.smooth_idf:\n",
    "                tf = BoW.toarray()\n",
    "                df = np.where(tf==0, 0, 1)\n",
    "                df = np.sum(df, axis=0)\n",
    "                idf = np.log((1 + tf.shape[0])/(1 + df)) + 1\n",
    "            \n",
    "            else:\n",
    "                tf = BoW.toarray()\n",
    "                df = np.where(tf==0, 0, 1)\n",
    "                df = np.sum(df, axis=0)\n",
    "                idf = np.log(tf.shape[0]/df) + 1\n",
    "        \n",
    "        return tf*idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $tf(t,d) = n_{t,d}$とした場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 2.09861229, 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        , 2.09861229],\n",
       "       [2.09861229, 2.09861229, 0.        , 2.        , 0.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scikit-learn(smooth_idf(-))\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "sentences = [\"This movie is SOOOO funny!!!\",\n",
    "   \"What a movie! I never\",\n",
    "   \"best movie ever!!!!! this movie\"]\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b',\n",
    "                             ngram_range=(1,1), \n",
    "                             stop_words=stop,\n",
    "                             max_features=5)\n",
    "tfidf = TfidfTransformer(norm=None, use_idf=True, smooth_idf=False)\n",
    "tfidf.fit_transform(vectorizer.fit_transform(sentences)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 2.09861229, 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        , 2.09861229],\n",
       "       [2.09861229, 2.09861229, 0.        , 2.        , 0.        ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scratch(smooth_idf(-))\n",
    "stfidf = ScratchTfidfTransformer(standard=False, smooth_idf=False)\n",
    "stfidf.fit_transform(vectorizer.fit_transform(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearnと一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 1.69314718, 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        , 1.69314718],\n",
       "       [1.69314718, 1.69314718, 0.        , 2.        , 0.        ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scikit-learn(smooth_idf(+))\n",
    "vectorizer = CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b',\n",
    "                             ngram_range=(1,1), \n",
    "                             stop_words=stop,\n",
    "                             max_features=5)\n",
    "tfidf = TfidfTransformer(norm=None, use_idf=True, smooth_idf=True)\n",
    "tfidf.fit_transform(vectorizer.fit_transform(sentences)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 1.69314718, 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        , 1.69314718],\n",
       "       [1.69314718, 1.69314718, 0.        , 2.        , 0.        ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scratch(smooth_idf(+))\n",
    "stfidf = ScratchTfidfTransformer(standard=False, smooth_idf=True)\n",
    "stfidf.fit_transform(vectorizer.fit_transform(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearnと一致"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. $tf(t,d) = \\frac{n_{t,d}}{\\sum_{s \\in d}n_{s,d}}$とした場合（標準式）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.54930614, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.54930614],\n",
       "       [0.27465307, 0.27465307, 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scratch(標準式)\n",
    "stfidf = ScratchTfidfTransformer(standard=True, smooth_idf=False)\n",
    "stfidf.fit_transform(vectorizer.fit_transform(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ＜Word2Vec＞\n",
    "\n",
    "ニューラルネットワークを用いてベクトル化を行う手法が **Word2Vec** です。\n",
    "\n",
    "\n",
    "BoWやTF-IDFはone-hot表現であったため、得られるベクトルの次元は語彙数分になります。そのため、語彙数を増やしにくいという問題があります。一方で、Word2Vecでは単語を任意の次元のベクトルに変換します。これをを **Word Embedding（単語埋め込み）** や **分散表現** と呼びます。変換操作を「ベクトル空間に埋め込む」と言うことが多いです。\n",
    "\n",
    "\n",
    "Word2VecにはCBoWとSkip-gramという2種類の仕組みがあるため順番に見ていきます。\n",
    "\n",
    "\n",
    "### ＜CBoW＞  \n",
    "**CBoW (Continuous Bag-of-Words)** によるWord2Vecではある単語とある単語の間に来る単語を推定できるように全結合層2層のニューラルネットワークを学習します。\n",
    "\n",
    "\n",
    "単語はコーパスの語彙数次元のone-hot表現を行なっておきます。そのため、入力と出力の次元は語彙数と同じになります。一方で、中間のノード数をWord2Vecにより得たい任意の次元数とします。これにより全結合層の重みは「得たい次元のノード数×語彙数」になります。このネットワークにより学習を行なった後、出力側の重みを取り出すことで、各語彙を表すベクトルを手に入れることができます。\n",
    "\n",
    "\n",
    "間の単語の推定を行なっているため、同じ箇所で代替可能な言葉は似たベクトルになるというメリットもあります。これはBoWやTF-IDFでは得られない情報です。\n",
    "\n",
    "\n",
    "あるテキストは「そのテキストの長さ（単語数）×Word2Vecで得た分散表現の次元数」の配列になりますが、各入力の配列を揃える必要があるモデルに入力するためには、短いテキストは空白を表す単語を加える **パディング** を行なったり、長いテキストは単語を消したりします。テキストを **固定長** にすると呼びます。\n",
    "\n",
    "\n",
    "### ＜ウィンドウサイズ＞  \n",
    "入力する単語は推定する前後1つずつだけでなく、複数個とする場合もあります。前後いくつを見るかの大きさを **ウィンドウサイズ** と呼びます。\n",
    "\n",
    "\n",
    "### ＜Skip-gram＞\n",
    "CBoWとは逆にある単語の前後の単語を推定できるように全結合層2層のニューラルネットワークを学習する方法が **Skip-gram** です。学習を行なった後は入力側の重みを取り出し各語彙を表すベクトルとします。現在一般的に使われているのはCBoWよりもSki-gramです。\n",
    "\n",
    "\n",
    "＜利用方法＞\n",
    "Pythonでは Gensim ライブラリを用いて扱うことができます。\n",
    "\n",
    "\n",
    "gensim: models.word2vec – Word2vec embeddings\n",
    "\n",
    "\n",
    "BoWの例と同じ文章で学習してみます。CountVectorizerと異なり前処理を自動的に行なってはくれないため、単語（トークン）はリストで分割しておきます。また、大文字は小文字に揃え、記号は取り除きます。\n",
    "\n",
    "\n",
    "デフォルトのパラメータではCBoWで計算されます。また、ウィンドウサイズは``window=5``に設定されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "語彙の一覧 : dict_keys(['this', 'movie', 'is', 'very', 'good', 'film', 'a', 'bad'])\n",
      "thisのベクトル : \n",
      "[-0.01905255  0.01222007  0.00753219  0.0183395  -0.04779945  0.00785236\n",
      "  0.03166589  0.03522122 -0.04954129  0.03939003]\n",
      "movieのベクトル : \n",
      "[-0.0285935  -0.01155855 -0.00848911  0.04618154  0.00953156 -0.01662322\n",
      "  0.0435673  -0.03860151  0.04951442  0.03097068]\n",
      "isのベクトル : \n",
      "[-0.02717231 -0.04253777  0.02598132  0.03928245  0.01133216 -0.0248255\n",
      " -0.0279754   0.03145223 -0.00216076  0.00348846]\n",
      "veryのベクトル : \n",
      "[-0.01574445 -0.02664172 -0.01968733  0.0065083   0.00405101 -0.04468705\n",
      "  0.01497423 -0.03469039 -0.02980079 -0.02279312]\n",
      "goodのベクトル : \n",
      "[-0.03948881  0.00803179 -0.00491202 -0.00719486 -0.01742625  0.02389831\n",
      "  0.00435047 -0.01361578  0.02715305  0.01317012]\n",
      "filmのベクトル : \n",
      "[-0.03342346 -0.03916999  0.03180332  0.00615893 -0.013058    0.02233667\n",
      "  0.023642    0.02284873 -0.02517154  0.00541141]\n",
      "aのベクトル : \n",
      "[-0.03477296  0.02347169 -0.02338103 -0.01725109 -0.00449602 -0.02106411\n",
      " -0.00620649  0.03511609 -0.04218159  0.04785145]\n",
      "badのベクトル : \n",
      "[-0.03926497 -0.0075279   0.03458725 -0.03273978 -0.01602179  0.00535445\n",
      " -0.04284631  0.03841916 -0.01074066 -0.04914357]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\tf115\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "sentences = [['this', 'movie', 'is', 'very', 'good'], ['this', 'film', 'is', 'a', 'good'], ['very', 'bad', 'very', 'very', 'bad']]\n",
    "model = Word2Vec(min_count=1, size=10) # 次元数を10に設定\n",
    "model.build_vocab(sentences) # 準備\n",
    "model.train(sentences, total_examples=model.corpus_count, epochs=model.iter) # 学習\n",
    "print(\"語彙の一覧 : {}\".format(model.wv.vocab.keys()))\n",
    "for vocab in model.wv.vocab.keys():\n",
    "    print(\"{}のベクトル : \\n{}\".format(vocab, model.wv[vocab]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このようにしてベクトルが得られます。\n",
    "\n",
    "\n",
    "### ＜単語の距離＞\n",
    "ベクトル間で計算を行うことで、ある単語に似たベクトルを持つ単語を見つけることができます。例えばgoodに似たベクトルの単語を3つ探します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movie', 0.4293789863586426),\n",
       " ('film', 0.15698349475860596),\n",
       " ('this', 0.09018419682979584)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=\"good\", topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今の例では3文しか学習していませんので効果を発揮しませんが、大きなコーパスで学習することで、並列関係のものが近くに来たりなど面白い結果が得られます。\n",
    "\n",
    "\n",
    "### ＜可視化＞\n",
    "2次元に圧縮することで単語ごとの位置関係を可視化することができます。以下はt-SNEを用いた例です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\tf115\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "vocabs = model.wv.vocab.keys()\n",
    "tsne_model = TSNE(perplexity=40, n_components=2, init=\"pca\", n_iter=5000, random_state=23)\n",
    "vectors_tsne = tsne_model.fit_transform(model[vocabs])\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.scatter(vectors_tsne[:, 0], vectors_tsne[:, 1])\n",
    "for i, word in enumerate(list(vocabs)):\n",
    "    plt.annotate(word, xy=(vectors_tsne[i, 0], vectors_tsne[i, 1]))\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ＜IMDB映画レビューデータセットの分散表現＞\n",
    "\n",
    "IMDB映画レビューデータセットの訓練データをコーパスとしてWord2Vecを学習させ分散表現を獲得しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】コーパスの前処理\n",
    "コーパスの前処理として、特殊文字（!など）やURLの除去、大文字の小文字化といったことを行なってください。また、単語（トークン）はリストで分割してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. <br /><br />Flawed but honest with a terrible honesty.\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : ['zero', 'day', 'leads', 'you', 'to', 'think', 'even', 're', 'think', 'why']\n",
      "test : ['don', 'hate', 'heather', 'graham', 'because', 'she', 'beautiful', 'hate', 'her', 'because']\n",
      "n_words : 50000\n"
     ]
    }
   ],
   "source": [
    "sentences_train = []\n",
    "sentences_test = []\n",
    "\n",
    "# 正規表現のfindallで取り出す\n",
    "for i in range(len(x_train)):\n",
    "    sentences_train.append(re.findall(r'(?u)\\b\\w\\w+\\b', x_train[i].lower()))\n",
    "for j in range(len(x_test)):\n",
    "    sentences_test.append(re.findall(r'(?u)\\b\\w\\w+\\b', x_test[j].lower()))\n",
    "    \n",
    "# 単語の例\n",
    "print('train :',sentences_train[0][:10])\n",
    "print('test :', sentences_test[0][:10])\n",
    "\n",
    "# 単語の種類数の確認 (set()で重複削除しようとしたがunhashableだった)\n",
    "sentences = sentences_train + sentences_test\n",
    "print('n_words :', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題6】Word2Vecの学習\n",
    "Word2Vecの学習を行なってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\tf115\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(42949189, 56131170)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train / testデータを統合して単語をベクトル化する\n",
    "# 次元数は500とする\n",
    "sentences = sentences_train + sentences_test\n",
    "model = Word2Vec(min_count=1, size=500)\n",
    "model.build_vocab(sentences)\n",
    "model.train(sentences, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "# 例\n",
    "print(model.wv['zero'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zero', 'day', 'leads', 'you', 'to', 'think', 'even', 're', 'why', 'two']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.wv.vocab.keys())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1単語が500次元のベクトルになっている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題7】ベクトルの可視化\n",
    "得られたベクトルをt-SNEにより可視化してください。また、いくつかの単語を選び``wv.most_similar``を用いて似ている単語を調べてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\tf115\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 40単語へ絞る\n",
    "vocabs = list(model.wv.vocab.keys())[:40]\n",
    "tsne_model = TSNE(perplexity=40, n_components=2, init=\"pca\", n_iter=250, random_state=23)\n",
    "vectors_tsne = tsne_model.fit_transform(model[vocabs])\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.scatter(vectors_tsne[:, 0], vectors_tsne[:, 1])\n",
    "for i, word in enumerate(list(vocabs)):\n",
    "    plt.annotate(word, xy=(vectors_tsne[i, 0], vectors_tsne[i, 1]))\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lowest', 0.553831934928894),\n",
       " ('definite', 0.5406824350357056),\n",
       " ('minimal', 0.5291178822517395)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zero\n",
    "model.wv.most_similar(positive=\"zero\", topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('animals', 0.7486428618431091),\n",
       " ('machines', 0.7122617959976196),\n",
       " ('creatures', 0.6946114301681519)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# humans\n",
    "model.wv.most_similar(positive=\"humans\", topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wealthy', 0.5834493637084961),\n",
       " ('troubled', 0.5457364320755005),\n",
       " ('elderly', 0.5271981358528137)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# young\n",
    "model.wv.most_similar(positive=\"young\", topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('colleagues', 0.8555325865745544),\n",
       " ('peers', 0.8250316381454468),\n",
       " ('girlfriends', 0.811843752861023)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classmates\n",
    "model.wv.most_similar(positive=\"classmates\", topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "何となく近しい感じはする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ＜学習済みベクトル＞\n",
    "巨大なコーパスで学習して得たベクトルも公開されているため、自分で学習をせずに利用することもできます。オリジナルのWord2Vecの他に同じ作者の発展系である FastText やスタンフォード大の GloVe があり、それぞれ公開されています。\n",
    "\n",
    "\n",
    "### 【問題8】Word2Vecを用いた映画レビューの分類\n",
    "問題6で学習して得たベクトルや公開されている学習済みベクトルを用いてIMDB映画レビューデータセットの感情分類の学習・推定を行なってください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ＜方針＞  \n",
    "学習したベクトルを用いる。  \n",
    "1単語が500次元のベクトルで表現されており、文章は単語の集合であるので、この単語ベクトルの和で文章が表現されると考える。  \n",
    "ただし文章によって単語数は異なるため、単に和をとったものと平均をとったものの2通りでデータを生成し、標準化をかけた後にロジスティック回帰で学習・推定し比較してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\tf115\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "C:\\Users\\USER\\anaconda3\\envs\\tf115\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\USER\\anaconda3\\envs\\tf115\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\USER\\anaconda3\\envs\\tf115\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# 和と平均でデータ作成\n",
    "X_train_s = np.empty([len(x_train), 500])\n",
    "X_train_m = np.empty([len(x_train), 500])\n",
    "X_test_s = np.empty([len(x_test), 500])\n",
    "X_test_m = np.empty([len(x_test), 500])\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    X_train_s[i, :] = np.sum(model[sentences_train[i]], axis=0)\n",
    "    X_train_m[i, :] = np.mean(model[sentences_train[i]], axis=0)\n",
    "\n",
    "for j in range(len(x_test)):\n",
    "    X_test_s[j, :] = np.sum(model[sentences_test[j]], axis=0)\n",
    "    X_test_m[j, :] = np.mean(model[sentences_test[j]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Logistic Regression ==\n",
      "Word2Vec(dimension=500, sum)\n",
      "Accuracy :  0.86504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\tf115\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# sumデータ\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train_s)\n",
    "X_test_std = sc.transform(X_test_s)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_std, y_train)\n",
    "print('== Logistic Regression ==')\n",
    "print('Word2Vec(dimension=500, sum)')\n",
    "print('Accuracy : ', lr.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Logistic Regression ==\n",
      "Word2Vec(dimension=500, mean)\n",
      "Accuracy :  0.86752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\tf115\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# meanデータ\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train_m)\n",
    "X_test_std = sc.transform(X_test_m)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_std, y_train)\n",
    "print('== Logistic Regression ==')\n",
    "print('Word2Vec(dimension=500, mean)')\n",
    "print('Accuracy : ', lr.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和でも平均でも 86% 程度の正答率は出ている。  \n",
    "Sentiment Classificationでは、単語ベクトルの和で文章が表せると考えて良さそうか。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
